#!/usr/bin/env python3
"""
K-Stock Insight ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸

pykrxë¥¼ ì‚¬ìš©í•´ì„œ í•œêµ­ ì£¼ì‹ ì‹œì¥ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  PostgreSQLì— ì €ì¥í•©ë‹ˆë‹¤.
- ì¢…ëª© ì •ë³´ (stocks)
- ì¼ë³„ ì‹œì„¸ (daily_prices) 
- íˆ¬ìì ë™í–¥ (investor_trends)
- ì„¹í„° ì •ë³´ (sectors)
- ì„¹í„°ë³„ ì‹œì„¸ (sector_prices)

Features:
- ì§„í–‰ë¥  ì‹¤ì‹œê°„ í‘œì‹œ (tqdm)
- ì¤‘ê°„ ì €ì¥ ê²°ê³¼ ì²´í¬
- ë°°ì¹˜ë³„ ì»¤ë°‹ìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´
- ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„
- ì„¤ì • ê°€ëŠ¥í•œ ìˆ˜ì§‘ ê¸°ê°„
"""

import os
import sys
import pandas as pd
import psycopg2
from datetime import datetime, timedelta
from typing import List, Dict, Any
import logging
import time
from tqdm import tqdm

# pykrx ëª¨ë“ˆ import
try:
    from pykrx import stock
except ImportError:
    print("pykrx ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install pykrx' ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_collection.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ============================
# ğŸ”§ ì„¤ì • ë³€ìˆ˜ (ì‰½ê²Œ ë³€ê²½ ê°€ëŠ¥)
# ============================

# ë°ì´í„° ìˆ˜ì§‘ ê¸°ê°„ ì„¤ì • (2025ë…„ 1ì›” 1ì¼ë¶€í„°)
START_DATE = '20250101'  # 2025ë…„ 1ì›” 1ì¼ë¶€í„°
END_DATE = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')  # ì–´ì œê¹Œì§€

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': os.getenv('DB_PORT', '5432'),
    'database': os.getenv('DB_NAME', 'k_stock_insight'),
    'user': os.getenv('DB_USER', 'hhhhp'),
    'password': os.getenv('DB_PASSWORD', '')
}

# ìˆ˜ì§‘í•  ì‹œì¥ êµ¬ë¶„
MARKETS = ['KOSPI', 'KOSDAQ']

# ì²˜ë¦¬ ì„¤ì •
BATCH_SIZE = 50  # ë°°ì¹˜ í¬ê¸° (ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°ì ˆ)
CHECK_INTERVAL = 100  # 100ê°œë§ˆë‹¤ ì €ì¥ ìƒíƒœ ì²´í¬
MAX_RETRIES = 3  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

class KRXDataCollector:
    def __init__(self):
        self.conn = None
        self.cursor = None
        self.total_processed = 0
        self.total_saved = 0
        self.total_failed = 0
        self.start_time = None
        self.connect_db()
        
    def connect_db(self):
        """PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        try:
            self.conn = psycopg2.connect(**DB_CONFIG)
            self.cursor = self.conn.cursor()
            logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            sys.exit(1)
    
    def close_db(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ"""
        if self.conn:
            self.conn.close()
            logger.info("ğŸ”š ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ")
    
    def collect_stocks_info(self) -> pd.DataFrame:
        """1. ìƒì¥ ì¢…ëª© ì •ë³´ ìˆ˜ì§‘"""
        logger.info("ğŸ“Š ìƒì¥ ì¢…ëª© ì •ë³´ ìˆ˜ì§‘ ì‹œì‘...")
        
        all_stocks = []
        
        for market in MARKETS:
            try:
                # ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                tickers = stock.get_market_ticker_list(market=market)
                logger.info(f"{market} ì¢…ëª© ìˆ˜: {len(tickers)}ê°œ")
                
                for ticker in tqdm(tickers, desc=f"{market} ì¢…ëª© ì •ë³´"):
                    try:
                        # ì¢…ëª©ëª… ê°€ì ¸ì˜¤ê¸°
                        name = stock.get_market_ticker_name(ticker)
                        
                        all_stocks.append({
                            'ticker': ticker,
                            'name': name,
                            'market': market,
                            'listed_date': None  # pykrxì—ì„œ ì§ì ‘ ì œê³µí•˜ì§€ ì•ŠìŒ
                        })
                        
                    except Exception as e:
                        logger.warning(f"ì¢…ëª© {ticker} ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                        continue
                        
            except Exception as e:
                logger.error(f"{market} ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                continue
        
        df = pd.DataFrame(all_stocks)
        logger.info(f"ì´ {len(df)}ê°œ ì¢…ëª© ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
        return df
    
    def collect_daily_prices(self, tickers: List[str]) -> int:
        """2. ì¼ë³„ ì‹œì„¸ ë°ì´í„° ìˆ˜ì§‘ (ì „ì²´ ì¢…ëª©)"""
        logger.info("ğŸ“ˆ ì¼ë³„ ì‹œì„¸ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        # ìˆ˜ì§‘ ê¸°ê°„ ê³„ì‚°
        start_dt = datetime.strptime(START_DATE, '%Y%m%d')
        end_dt = datetime.strptime(END_DATE, '%Y%m%d')
        period_days = (end_dt - start_dt).days + 1
        
        logger.info(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {START_DATE} ~ {END_DATE} ({period_days}ì¼)")
        
        self.start_time = time.time()
        total_saved_records = 0
        processed_count = 0
        batch_saved = 0
        
        # ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•œ tqdm ì‚¬ìš©
        pbar = tqdm(tickers, desc="ì‹œì„¸ ë°ì´í„° ìˆ˜ì§‘", unit="ì¢…ëª©")
        
        for ticker in pbar:
            try:
                # ì¢…ëª©ë³„ OHLCV ë°ì´í„° ìˆ˜ì§‘
                df = stock.get_market_ohlcv_by_date(START_DATE, END_DATE, ticker)
                
                if not df.empty:
                    df = df.reset_index()
                    df['ticker'] = ticker
                    
                    # ì»¬ëŸ¼ëª… ë§¤í•‘
                    df.rename(columns={
                        'ë‚ ì§œ': 'date',
                        'ì‹œê°€': 'open',
                        'ê³ ê°€': 'high', 
                        'ì €ê°€': 'low',
                        'ì¢…ê°€': 'close',
                        'ê±°ë˜ëŸ‰': 'volume'
                    }, inplace=True)
                    
                    # DB ì €ì¥
                    saved_count = 0
                    for _, row in df.iterrows():
                        query = """
                        INSERT INTO daily_prices (ticker, date, open, high, low, close, volume) 
                        VALUES (%s, %s, %s, %s, %s, %s, %s) 
                        ON CONFLICT (ticker, date) DO UPDATE SET 
                        open = EXCLUDED.open, high = EXCLUDED.high, low = EXCLUDED.low, 
                        close = EXCLUDED.close, volume = EXCLUDED.volume
                        """
                        
                        self.cursor.execute(query, (
                            row['ticker'], row['date'], row['open'], 
                            row['high'], row['low'], row['close'], row['volume']
                        ))
                        saved_count += 1
                    
                    total_saved_records += saved_count
                    batch_saved += saved_count
                    
                    # tqdm ì„¤ëª… ì—…ë°ì´íŠ¸
                    pbar.set_postfix({
                        'records': f'{total_saved_records:,}',
                        'failed': self.total_failed
                    })
                    
                else:
                    self.total_failed += 1
                
                processed_count += 1
                
                # ë°°ì¹˜ë§ˆë‹¤ ì»¤ë°‹
                if processed_count % BATCH_SIZE == 0:
                    self.conn.commit()
                    logger.info(f"ğŸ’¾ ë°°ì¹˜ ì»¤ë°‹: {batch_saved}ê°œ ë ˆì½”ë“œ ì €ì¥")
                    batch_saved = 0
                
                # ì£¼ê¸°ì  ì§„í–‰ ìƒí™© ì²´í¬
                if processed_count % CHECK_INTERVAL == 0:
                    self.check_progress(processed_count, len(tickers), total_saved_records)
                    
            except Exception as e:
                self.total_failed += 1
                logger.warning(f"ì¢…ëª© {ticker} ì‹œì„¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                continue
        
        # ìµœì¢… ì»¤ë°‹
        self.conn.commit()
        
        logger.info(f"âœ… ì´ {total_saved_records:,}ê°œ ì‹œì„¸ ë°ì´í„° ì €ì¥ ì™„ë£Œ!")
        return total_saved_records
    
    def check_progress(self, processed: int, total: int, saved_records: int):
        """ì§„í–‰ë¥  ë° ì €ì¥ ìƒíƒœ ì²´í¬"""
        elapsed_time = time.time() - self.start_time
        progress_percent = (processed / total) * 100
        
        # ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ ê³„ì‚°
        if processed > 0:
            avg_time_per_ticker = elapsed_time / processed
            remaining_tickers = total - processed
            estimated_remaining = remaining_tickers * avg_time_per_ticker
            
            logger.info(f"ğŸ“ˆ ì§„í–‰ë¥ : {processed}/{total} ({progress_percent:.1f}%)")
            logger.info(f"â±ï¸ ê²½ê³¼ ì‹œê°„: {elapsed_time/60:.1f}ë¶„")
            logger.info(f"ğŸ• ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {estimated_remaining/60:.1f}ë¶„")
            logger.info(f"ğŸ’¾ ì €ì¥ëœ ë ˆì½”ë“œ: {saved_records:,}ê°œ")
            logger.info(f"âŒ ì‹¤íŒ¨í•œ ì¢…ëª©: {self.total_failed}ê°œ")
        
        # í˜„ì¬ DB ìƒíƒœ í™•ì¸
        self.cursor.execute("SELECT COUNT(*) FROM daily_prices")
        total_db_records = self.cursor.fetchone()[0]
        
        # ìµœê·¼ ì €ì¥ëœ ì¢…ëª©ë“¤
        self.cursor.execute("""
            SELECT ticker, COUNT(*) as records, MAX(date) as latest_date
            FROM daily_prices 
            GROUP BY ticker 
            ORDER BY MAX(created_at) DESC 
            LIMIT 5
        """)
        
        recent_data = self.cursor.fetchall()
        logger.info(f"ğŸ—„ï¸ DB ì´ ë ˆì½”ë“œ: {total_db_records:,}ê°œ")
        logger.info("ğŸ“… ìµœê·¼ ì €ì¥ëœ ì¢…ëª©ë“¤:")
        for ticker, records, latest_date in recent_data:
            logger.info(f"  - {ticker}: {records}ê°œ, ìµœì‹ ì¼ {latest_date}")
        
        logger.info("-" * 50)
    
    def collect_investor_trends(self, tickers: List[str]) -> int:
        """3. íˆ¬ìì ë™í–¥ ë°ì´í„° ìˆ˜ì§‘"""
        logger.info("ğŸ‘¥ íˆ¬ìì ë™í–¥ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        # ìˆ˜ì§‘ ê¸°ê°„ ê³„ì‚°
        start_dt = datetime.strptime(START_DATE, '%Y%m%d')
        end_dt = datetime.strptime(END_DATE, '%Y%m%d')
        period_days = (end_dt - start_dt).days + 1
        
        logger.info(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {START_DATE} ~ {END_DATE} ({period_days}ì¼)")
        
        total_saved_records = 0
        processed_count = 0
        batch_saved = 0
        
        # ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•œ tqdm ì‚¬ìš©
        pbar = tqdm(tickers, desc="íˆ¬ìì ë™í–¥ ìˆ˜ì§‘", unit="ì¢…ëª©")
        
        for ticker in pbar:
            try:
                # íˆ¬ììë³„ ê±°ë˜ ë°ì´í„° ìˆ˜ì§‘
                df = stock.get_market_net_purchases_of_equities_by_ticker(START_DATE, END_DATE, ticker)
                
                if not df.empty:
                    df = df.reset_index()
                    df['ticker'] = ticker
                    
                    # ì»¬ëŸ¼ëª… í™•ì¸ ë° ë§¤í•‘
                    logger.debug(f"íˆ¬ìì ë™í–¥ ë°ì´í„° ì»¬ëŸ¼: {list(df.columns)}")
                    
                    # pykrx ì»¬ëŸ¼ëª…ì„ DB ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë§¤í•‘
                    column_mapping = {
                        'ë‚ ì§œ': 'date',
                        'ê¸°ê´€ê³„': 'institution_net',
                        'ê¸°íƒ€ë²•ì¸': 'other_corp_net', 
                        'ê°œì¸': 'individual_net',
                        'ì™¸êµ­ì¸ê³„': 'foreign_net',
                        'ì „ì²´': 'total_net'
                    }
                    
                    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ë§¤í•‘
                    existing_mapping = {k: v for k, v in column_mapping.items() if k in df.columns}
                    df.rename(columns=existing_mapping, inplace=True)
                    
                    # DB ì €ì¥
                    saved_count = 0
                    for _, row in df.iterrows():
                        # ê¸°ë³¸ê°’ ì„¤ì •
                        data_dict = {
                            'ticker': row['ticker'],
                            'date': row.get('date', row.name if 'date' not in row else None),
                            'foreign_buy': 0,
                            'foreign_sell': 0,
                            'foreign_net': row.get('foreign_net', 0),
                            'institution_buy': 0,
                            'institution_sell': 0, 
                            'institution_net': row.get('institution_net', 0),
                            'individual_buy': 0,
                            'individual_sell': 0,
                            'individual_net': row.get('individual_net', 0)
                        }
                        
                        query = """
                        INSERT INTO investor_trends 
                        (ticker, date, foreign_buy, foreign_sell, foreign_net, 
                         institution_buy, institution_sell, institution_net,
                         individual_buy, individual_sell, individual_net) 
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s) 
                        ON CONFLICT (ticker, date) DO UPDATE SET 
                        foreign_net = EXCLUDED.foreign_net,
                        institution_net = EXCLUDED.institution_net,
                        individual_net = EXCLUDED.individual_net
                        """
                        
                        try:
                            self.cursor.execute(query, (
                                data_dict['ticker'], data_dict['date'],
                                data_dict['foreign_buy'], data_dict['foreign_sell'], data_dict['foreign_net'],
                                data_dict['institution_buy'], data_dict['institution_sell'], data_dict['institution_net'],
                                data_dict['individual_buy'], data_dict['individual_sell'], data_dict['individual_net']
                            ))
                            saved_count += 1
                        except Exception as e:
                            logger.warning(f"ì¢…ëª© {ticker} ë‚ ì§œ {data_dict['date']} ì €ì¥ ì‹¤íŒ¨: {e}")
                            continue
                    
                    total_saved_records += saved_count
                    batch_saved += saved_count
                    
                    # tqdm ì„¤ëª… ì—…ë°ì´íŠ¸
                    pbar.set_postfix({
                        'records': f'{total_saved_records:,}',
                        'failed': self.total_failed
                    })
                    
                else:
                    self.total_failed += 1
                
                processed_count += 1
                
                # ë°°ì¹˜ë§ˆë‹¤ ì»¤ë°‹
                if processed_count % BATCH_SIZE == 0:
                    self.conn.commit()
                    logger.info(f"ğŸ’¾ íˆ¬ìì ë™í–¥ ë°°ì¹˜ ì»¤ë°‹: {batch_saved}ê°œ ë ˆì½”ë“œ ì €ì¥")
                    batch_saved = 0
                
                # ì£¼ê¸°ì  ì§„í–‰ ìƒí™© ì²´í¬
                if processed_count % CHECK_INTERVAL == 0:
                    self.check_investor_progress(processed_count, len(tickers), total_saved_records)
                    
            except Exception as e:
                self.total_failed += 1
                logger.warning(f"ì¢…ëª© {ticker} íˆ¬ìì ë™í–¥ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                continue
        
        # ìµœì¢… ì»¤ë°‹
        self.conn.commit()
        
        logger.info(f"âœ… ì´ {total_saved_records:,}ê°œ íˆ¬ìì ë™í–¥ ë°ì´í„° ì €ì¥ ì™„ë£Œ!")
        return total_saved_records
    
    def check_investor_progress(self, processed: int, total: int, saved_records: int):
        """íˆ¬ìì ë™í–¥ ìˆ˜ì§‘ ì§„í–‰ë¥  ì²´í¬"""
        progress_percent = (processed / total) * 100
        
        logger.info(f"ğŸ‘¥ íˆ¬ìì ë™í–¥ ì§„í–‰ë¥ : {processed}/{total} ({progress_percent:.1f}%)")
        logger.info(f"ğŸ’¾ ì €ì¥ëœ íˆ¬ìì ë™í–¥ ë ˆì½”ë“œ: {saved_records:,}ê°œ")
        
        # í˜„ì¬ DB ìƒíƒœ í™•ì¸
        self.cursor.execute("SELECT COUNT(*) FROM investor_trends")
        total_db_records = self.cursor.fetchone()[0]
        
        logger.info(f"ğŸ—„ï¸ íˆ¬ìì ë™í–¥ DB ì´ ë ˆì½”ë“œ: {total_db_records:,}ê°œ")
        logger.info("-" * 50)
    
    def collect_sectors_info(self) -> pd.DataFrame:
        """4. ì„¹í„°(ì—…ì¢…) ì •ë³´ ìˆ˜ì§‘"""
        logger.info("ğŸ¢ ì„¹í„° ì •ë³´ ìˆ˜ì§‘ ì‹œì‘...")
        
        all_sectors = []
        
        try:
            # ì—…ì¢… ì§€ìˆ˜ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            sector_codes = stock.get_index_ticker_list(market="KOSPI")
            
            for sector_code in tqdm(sector_codes, desc="ì„¹í„° ì •ë³´ ìˆ˜ì§‘"):
                try:
                    # ì„¹í„°ëª… ê°€ì ¸ì˜¤ê¸°
                    sector_name = stock.get_index_ticker_name(sector_code)
                    
                    all_sectors.append({
                        'sector_code': sector_code,
                        'sector_name': sector_name,
                        'ticker': None  # êµ¬ì„±ì¢…ëª©ì€ ë³„ë„ ì²˜ë¦¬
                    })
                        
                except Exception as e:
                    logger.warning(f"ì„¹í„° {sector_code} ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"ì„¹í„° ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        df = pd.DataFrame(all_sectors)
        logger.info(f"ì´ {len(df)}ê°œ ì„¹í„° ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        return df
    
    def collect_sector_prices(self) -> int:
        """5. ì—…ì¢…ë³„ ì‹œì„¸ ë°ì´í„° ìˆ˜ì§‘"""
        logger.info("ğŸ¢ ì—…ì¢…ë³„ ì‹œì„¸ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        start_dt = datetime.strptime(START_DATE, '%Y%m%d')
        end_dt = datetime.strptime(END_DATE, '%Y%m%d')
        period_days = (end_dt - start_dt).days + 1
        
        logger.info(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {START_DATE} ~ {END_DATE} ({period_days}ì¼)")
        
        total_saved_records = 0
        
        try:
            # ì—…ì¢… ì§€ìˆ˜ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            sector_codes = stock.get_index_ticker_list(market="KOSPI")
            logger.info(f"ğŸ“Š ëŒ€ìƒ ì—…ì¢… ìˆ˜: {len(sector_codes)}ê°œ")
            
            pbar = tqdm(sector_codes, desc="ì—…ì¢… ì‹œì„¸ ìˆ˜ì§‘", unit="ì—…ì¢…")
            
            for sector_code in pbar:
                try:
                    # ì—…ì¢…ëª… ê°€ì ¸ì˜¤ê¸°
                    sector_name = stock.get_index_ticker_name(sector_code)
                    
                    # ì—…ì¢…ë³„ OHLCV ë°ì´í„° ìˆ˜ì§‘
                    df = stock.get_index_ohlcv_by_date(START_DATE, END_DATE, sector_code)
                    
                    if not df.empty:
                        df = df.reset_index()
                        
                        # ê° ë‚ ì§œë³„ë¡œ ì €ì¥
                        for _, row in df.iterrows():
                            date_val = row['ë‚ ì§œ'] if 'ë‚ ì§œ' in row else row.name
                            
                            query = """
                            INSERT INTO sector_prices 
                            (sector_code, sector_name, date, open, high, low, close, volume) 
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s) 
                            ON CONFLICT (sector_code, date) DO UPDATE SET 
                            sector_name = EXCLUDED.sector_name,
                            open = EXCLUDED.open, high = EXCLUDED.high, 
                            low = EXCLUDED.low, close = EXCLUDED.close, 
                            volume = EXCLUDED.volume
                            """
                            
                            # ì»¬ëŸ¼ëª… ë§¤í•‘
                            open_val = row['ì‹œê°€'] if 'ì‹œê°€' in row else row.get('open', 0)
                            high_val = row['ê³ ê°€'] if 'ê³ ê°€' in row else row.get('high', 0)
                            low_val = row['ì €ê°€'] if 'ì €ê°€' in row else row.get('low', 0)
                            close_val = row['ì¢…ê°€'] if 'ì¢…ê°€' in row else row.get('close', 0)
                            volume_val = row['ê±°ë˜ëŸ‰'] if 'ê±°ë˜ëŸ‰' in row else row.get('volume', 0)
                            
                            self.cursor.execute(query, (
                                sector_code, sector_name, date_val,
                                int(open_val), int(high_val), int(low_val), 
                                int(close_val), int(volume_val)
                            ))
                            total_saved_records += 1
                        
                        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                        pbar.set_postfix({'records': f'{total_saved_records:,}'})
                        
                        # ì£¼ê¸°ì  ì»¤ë°‹
                        if total_saved_records % 1000 == 0:
                            self.conn.commit()
                            
                except Exception as e:
                    logger.warning(f"ì—…ì¢… {sector_code} ì‹œì„¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
            
            # ìµœì¢… ì»¤ë°‹
            self.conn.commit()
            logger.info(f"âœ… ì´ {total_saved_records:,}ê°œ ì—…ì¢… ì‹œì„¸ ë ˆì½”ë“œ ì €ì¥ ì™„ë£Œ!")
            
        except Exception as e:
            logger.error(f"ì—…ì¢… ì‹œì„¸ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            
        return total_saved_records
    
    def save_to_db(self, df: pd.DataFrame, table_name: str):
        """ë°ì´í„°í”„ë ˆì„ì„ PostgreSQL í…Œì´ë¸”ì— ì €ì¥"""
        if df.empty:
            logger.warning(f"{table_name} í…Œì´ë¸”ì— ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        try:
            cursor = self.conn.cursor()
            
            # í…Œì´ë¸”ë³„ INSERT ì¿¼ë¦¬ ìƒì„±
            if table_name == 'stocks':
                query = """
                INSERT INTO stocks (ticker, name, market, listed_date) 
                VALUES (%s, %s, %s, %s) 
                ON CONFLICT (ticker) DO UPDATE SET 
                name = EXCLUDED.name, market = EXCLUDED.market
                """
                data = [(row['ticker'], row['name'], row['market'], row['listed_date']) 
                       for _, row in df.iterrows()]
                
            elif table_name == 'sectors':
                query = """
                INSERT INTO sectors (sector_code, sector_name, ticker) 
                VALUES (%s, %s, %s) 
                ON CONFLICT (sector_code, ticker) DO NOTHING
                """
                data = [(row['sector_code'], row['sector_name'], row['ticker']) 
                       for _, row in df.iterrows()]
                
            else:
                logger.warning(f"í…Œì´ë¸” {table_name}ì— ëŒ€í•œ INSERT ì¿¼ë¦¬ê°€ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return
            
            cursor.executemany(query, data)
            self.conn.commit()
            logger.info(f"âœ… {table_name} í…Œì´ë¸”ì— {len(data)}ê°œ ë ˆì½”ë“œ ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ {table_name} í…Œì´ë¸” ì €ì¥ ì‹¤íŒ¨: {e}")
            self.conn.rollback()
    
    def final_database_check(self):
        """ìµœì¢… ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸"""
        logger.info("\nğŸ“‹ ìµœì¢… ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ:")
        
        # ì¼ë³„ ì‹œì„¸ ë°ì´í„° ìƒíƒœ
        self.cursor.execute("SELECT COUNT(*) FROM daily_prices")
        total_prices = self.cursor.fetchone()[0]
        
        # íˆ¬ìì ë™í–¥ ë°ì´í„° ìƒíƒœ  
        self.cursor.execute("SELECT COUNT(*) FROM investor_trends")
        total_trends = self.cursor.fetchone()[0]
        
        # ì—…ì¢…ë³„ ì‹œì„¸ ë°ì´í„° ìƒíƒœ
        self.cursor.execute("SELECT COUNT(*) FROM sector_prices")
        total_sectors = self.cursor.fetchone()[0]
        
        # ì¢…ëª©ë³„ í†µê³„
        self.cursor.execute("""
            SELECT COUNT(DISTINCT ticker) as unique_tickers,
                   MIN(date) as earliest_date,
                   MAX(date) as latest_date,
                   AVG(volume) as avg_volume
            FROM daily_prices
        """)
        stats = self.cursor.fetchone()
        
        logger.info(f"ğŸ“ˆ ì¼ë³„ ì‹œì„¸ ë ˆì½”ë“œ: {total_prices:,}ê°œ")
        logger.info(f"ğŸ‘¥ íˆ¬ìì ë™í–¥ ë ˆì½”ë“œ: {total_trends:,}ê°œ")
        logger.info(f"ğŸ¢ ì—…ì¢…ë³„ ì‹œì„¸ ë ˆì½”ë“œ: {total_sectors:,}ê°œ")
        logger.info(f"ğŸ“Š ìˆ˜ì§‘ëœ ì¢…ëª© ìˆ˜: {stats[0]:,}ê°œ")
        logger.info(f"ğŸ“… ë°ì´í„° ê¸°ê°„: {stats[1]} ~ {stats[2]}")
        logger.info(f"ğŸ’¹ í‰ê·  ê±°ë˜ëŸ‰: {int(stats[3]):,}ì£¼")
        
        # ìƒìœ„ ê±°ë˜ëŸ‰ ì¢…ëª©ë“¤
        self.cursor.execute("""
            SELECT s.ticker, s.name, AVG(dp.volume) as avg_volume
            FROM daily_prices dp
            JOIN stocks s ON dp.ticker = s.ticker
            GROUP BY s.ticker, s.name
            ORDER BY avg_volume DESC
            LIMIT 5
        """)
        
        top_volume = self.cursor.fetchall()
        logger.info("\nğŸ”¥ í‰ê·  ê±°ë˜ëŸ‰ ìƒìœ„ 5ê°œ ì¢…ëª©:")
        for ticker, name, avg_vol in top_volume:
            logger.info(f"  {ticker} ({name}): {int(avg_vol):,}ì£¼")
        
        # íˆ¬ìì ë™í–¥ ìƒ˜í”Œ í™•ì¸
        self.cursor.execute("""
            SELECT ticker, date, investor_type, net_value
            FROM investor_trends 
            ORDER BY date DESC, ABS(net_value) DESC
            LIMIT 5
        """)
        
        top_trends = self.cursor.fetchall()
        if top_trends:
            logger.info("\nğŸ‘¥ ìµœê·¼ ìˆœë§¤ìˆ˜ ìƒìœ„ 5ê°œ:")
            for ticker, date, investor_type, net_value in top_trends:
                logger.info(f"  {ticker} ({date}): {investor_type} {net_value:,}")
        
        # ì—…ì¢…ë³„ ì‹œì„¸ ìƒ˜í”Œ í™•ì¸
        self.cursor.execute("""
            SELECT sector_code, sector_name, COUNT(*) as records,
                   MIN(date) as start_date, MAX(date) as end_date
            FROM sector_prices 
            GROUP BY sector_code, sector_name
            ORDER BY records DESC
            LIMIT 5
        """)
        
        top_sectors = self.cursor.fetchall()
        if top_sectors:
            logger.info("\nğŸ¢ ì—…ì¢…ë³„ ì‹œì„¸ ìƒìœ„ 5ê°œ:")
            for sector_code, sector_name, records, start_date, end_date in top_sectors:
                logger.info(f"  {sector_code} ({sector_name}): {records:,}ê°œ ({start_date} ~ {end_date})")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ìˆ˜ì§‘ ê¸°ê°„ ê³„ì‚°
    start_dt = datetime.strptime(START_DATE, '%Y%m%d')
    end_dt = datetime.strptime(END_DATE, '%Y%m%d')
    period_days = (end_dt - start_dt).days + 1
    
    logger.info("ğŸš€ K-Stock Insight ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    logger.info(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {START_DATE} ~ {END_DATE} ({period_days}ì¼)")
    
    collector = KRXDataCollector()
    
    try:
        # 1. ì¢…ëª© ì •ë³´ ìˆ˜ì§‘ (ì²˜ìŒì—ë§Œ í•„ìš”)
        stocks_df = collector.collect_stocks_info()
        if not stocks_df.empty:
            collector.save_to_db(stocks_df, 'stocks')
            tickers = stocks_df['ticker'].tolist()
        else:
            # ì´ë¯¸ ì €ì¥ëœ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
            collector.cursor.execute("SELECT ticker FROM stocks ORDER BY ticker")
            tickers = [row[0] for row in collector.cursor.fetchall()]
            logger.info(f"ê¸°ì¡´ ì €ì¥ëœ {len(tickers)}ê°œ ì¢…ëª© ì‚¬ìš©")
        
        if not tickers:
            logger.error("âŒ ì¢…ëª© ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 2. ì¼ë³„ ì‹œì„¸ ìˆ˜ì§‘ (ë©”ì¸ ì‘ì—…)
        total_saved = collector.collect_daily_prices(tickers)
        
        # 3. íˆ¬ìì ë™í–¥ ìˆ˜ì§‘
        investor_saved = collector.collect_investor_trends(tickers)
        
        # 4. ì„¹í„° ì •ë³´ ìˆ˜ì§‘
        sectors_df = collector.collect_sectors_info()
        if not sectors_df.empty:
            collector.save_to_db(sectors_df, 'sectors')
        
        # 5. ì—…ì¢…ë³„ ì‹œì„¸ ìˆ˜ì§‘
        sector_saved = collector.collect_sector_prices()
        
        # 6. ìµœì¢… ìƒíƒœ í™•ì¸
        collector.final_database_check()
        
        logger.info("âœ… ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
    finally:
        collector.close_db()

if __name__ == "__main__":
    main() 